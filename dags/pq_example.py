# excel_powerquery_etl.py
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator

class ExcelPowerQuery:
    """
    Power Query-style —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –¥–ª—è Excel —Ñ–∞–π–ª–æ–≤ —Å –ø–æ—à–∞–≥–æ–≤–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
    """
    
    def __init__(self, excel_path: str, sheet_name: str = 0):
        self.excel_path = excel_path
        self.sheet_name = sheet_name
        self.original_df = None
        self.current_df = None
        self.steps = []
        self.step_counter = 0
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        self._load_excel()
    
    def _load_excel(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel"""
        print("üì• –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ò–ó EXCEL")
        print(f"–§–∞–π–ª: {self.excel_path}")
        
        try:
            # –ß–∏—Ç–∞–µ–º Excel —Ñ–∞–π–ª
            self.original_df = pd.read_excel(self.excel_path, sheet_name=self.sheet_name, header=None)
            self.current_df = self.original_df.copy()
            
            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
            print(f"üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {self.original_df.shape}")
            print(f"üìã –õ–∏—Å—Ç: {self.sheet_name}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É Excel
            self._analyze_excel_structure()
            
            # –î–æ–±–∞–≤–ª—è–µ–º —à–∞–≥ –∑–∞–≥—Ä—É–∑–∫–∏
            self._add_step("Source", self.original_df, f"–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ Excel: {self.excel_path}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            raise
    
    def _analyze_excel_structure(self):
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Excel —Ñ–∞–π–ª–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤"""
        print("\nüîç –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ EXCEL")
        
        # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
        header_row = None
        for i in range(min(10, len(self.original_df))):
            row_values = [str(x) for x in self.original_df.iloc[i] if pd.notna(x)]
            non_empty_count = len(row_values)
            print(f"–°—Ç—Ä–æ–∫–∞ {i}: {non_empty_count} –Ω–µ–ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π ‚Üí {row_values[:5]}...")
            
            if non_empty_count >= 3:  # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                header_row = i
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ —Å—Ç—Ä–æ–∫–µ {i}")
                break
        
        self.header_row = header_row if header_row is not None else 0
        
        # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
        self.original_df = pd.read_excel(
            self.excel_path, 
            sheet_name=self.sheet_name, 
            header=self.header_row
        )
        self.current_df = self.original_df.copy()
    
    def _add_step(self, step_type: str, result_df: pd.DataFrame, description: str, details: dict = None):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —à–∞–≥ –≤ –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π"""
        self.step_counter += 1
        
        step_info = {
            'step_number': self.step_counter,
            'step_type': step_type,
            'description': description,
            'shape_before': self.current_df.shape if hasattr(self, 'current_df') else (0, 0),
            'shape_after': result_df.shape,
            'columns_before': list(self.current_df.columns) if hasattr(self, 'current_df') else [],
            'columns_after': list(result_df.columns),
            'preview_data': result_df.head(5).copy(),
            'details': details or {},
            'timestamp': datetime.now().strftime("%H:%M:%S")
        }
        
        self.steps.append(step_info)
        self.current_df = result_df.copy()
    
    def show_pipeline(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π"""
        print("\n" + "=" * 100)
        print("üè≠ –ü–ê–ô–ü–õ–ê–ô–ù –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ô POWER QUERY")
        print("=" * 100)
        
        for step in self.steps:
            print(f"\nüéØ –®–ê–ì {step['step_number']}: {step['description']}")
            print(f"   ‚è∞ {step['timestamp']} | üìê {step['shape_before']} ‚Üí {step['shape_after']}")
            
            # –î–µ—Ç–∞–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π
            if step['shape_before'] != step['shape_after']:
                rows_diff = step['shape_after'][0] - step['shape_before'][0]
                cols_diff = step['shape_after'][1] - step['shape_before'][1]
                
                if rows_diff != 0:
                    print(f"   üìä –°—Ç—Ä–æ–∫–∏: {step['shape_before'][0]} ‚Üí {step['shape_after'][0]} ({rows_diff:+d})")
                if cols_diff != 0:
                    print(f"   üìä –ö–æ–ª–æ–Ω–∫–∏: {step['shape_before'][1]} ‚Üí {step['shape_after'][1]} ({cols_diff:+d})")
            
            # –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
            if step['columns_before'] != step['columns_after']:
                added = set(step['columns_after']) - set(step['columns_before'])
                removed = set(step['columns_before']) - set(step['columns_after'])
                
                if added:
                    print(f"   ‚ûï –î–æ–±–∞–≤–ª–µ–Ω—ã: {list(added)}")
                if removed:
                    print(f"   ‚ûñ –£–¥–∞–ª–µ–Ω—ã: {list(removed)}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏
            if step['details']:
                print(f"   üìã –î–µ—Ç–∞–ª–∏: {step['details']}")
            
            print(f"   üëÄ PREVIEW –¥–∞–Ω–Ω—ã—Ö:")
            print(step['preview_data'].to_string(index=False))
            print("-" * 80)
    
    # –ú–ï–¢–û–î–´ –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ô
    
    def remove_columns(self, columns: list):
        """–£–¥–∞–ª—è–µ—Ç —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏"""
        df_result = self.current_df.drop(columns=columns, errors='ignore')
        self._add_step(
            "Remove Columns", 
            df_result, 
            f"–£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫",
            {'removed_columns': columns, 'count': len(columns)}
        )
        return self
    
    def keep_columns(self, columns: list):
        """–û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏"""
        df_result = self.current_df[columns]
        removed_columns = set(self.current_df.columns) - set(columns)
        self._add_step(
            "Keep Columns", 
            df_result, 
            f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–æ–ª–æ–Ω–æ–∫",
            {'kept_columns': columns, 'removed_columns': list(removed_columns)}
        )
        return self
    
    def rename_columns(self, column_mapping: dict):
        """–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç –∫–æ–ª–æ–Ω–∫–∏"""
        df_result = self.current_df.rename(columns=column_mapping)
        self._add_step(
            "Rename Columns", 
            df_result, 
            f"–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫",
            {'mapping': column_mapping}
        )
        return self
    
    def clean_column_names(self):
        """–û—á–∏—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ (—Ç–æ–ª—å–∫–æ Unnamed, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å)"""
        new_columns = {}
        for col in self.current_df.columns:
            if 'Unnamed' in str(col):
                # –î–ª—è Unnamed –∫–æ–ª–æ–Ω–æ–∫ —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ –∏–º–µ–Ω–∞
                new_columns[col] = f'column_{list(self.current_df.columns).index(col)}'
            else:
                # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                new_columns[col] = str(col).strip()
        
        df_result = self.current_df.rename(columns=new_columns)
        self._add_step(
            "Clean Names", 
            df_result, 
            f"–û—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫",
            {'new_names': new_columns}
        )
        return self
    
    def filter_rows(self, condition: str):
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ –ø–æ —É—Å–ª–æ–≤–∏—é"""
        initial_count = len(self.current_df)
        df_result = self.current_df.query(condition)
        removed_count = initial_count - len(df_result)
        
        self._add_step(
            "Filter Rows", 
            df_result, 
            f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—Ç—Ä–æ–∫",
            {'condition': condition, 'removed_rows': removed_count, 'kept_rows': len(df_result)}
        )
        return self
    
    def filter_rows_advanced(self, mask):
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–∞—Å–∫–∏"""
        initial_count = len(self.current_df)
        df_result = self.current_df[mask]
        removed_count = initial_count - len(df_result)
        
        self._add_step(
            "Filter Rows Advanced", 
            df_result, 
            f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—Ç—Ä–æ–∫ (advanced)",
            {'removed_rows': removed_count, 'kept_rows': len(df_result)}
        )
        return self
    
    def remove_empty_rows(self):
        """–£–¥–∞–ª—è–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏"""
        initial_count = len(self.current_df)
        df_result = self.current_df.dropna(how='all')
        removed_count = initial_count - len(df_result)
        
        self._add_step(
            "Remove Empty Rows", 
            df_result, 
            f"–£–¥–∞–ª–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫",
            {'removed_empty_rows': removed_count}
        )
        return self
    
    def remove_empty_columns(self):
        """–£–¥–∞–ª—è–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ –∫–æ–ª–æ–Ω–∫–∏"""
        initial_columns = len(self.current_df.columns)
        df_result = self.current_df.dropna(axis=1, how='all')
        removed_count = initial_columns - len(df_result.columns)
        
        self._add_step(
            "Remove Empty Columns", 
            df_result, 
            f"–£–¥–∞–ª–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –∫–æ–ª–æ–Ω–æ–∫",
            {'removed_empty_columns': removed_count}
        )
        return self
    
    def add_calculated_column(self, column_name: str, expression: callable):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –≤—ã—á–∏—Å–ª—è–µ–º—É—é –∫–æ–ª–æ–Ω–∫—É"""
        df_result = self.current_df.assign(**{column_name: expression})
        self._add_step(
            "Add Column", 
            df_result, 
            f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏: {column_name}",
            {'new_column': column_name, 'expression': expression.__name__ if hasattr(expression, '__name__') else 'lambda'}
        )
        return self
    
    def change_data_type(self, column: str, new_type: str):
        """–ò–∑–º–µ–Ω—è–µ—Ç —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∏"""
        df_result = self.current_df.copy()
        
        type_mapping = {
            'int': 'int32', 'float': 'float64', 'str': 'str',
            'datetime': 'datetime64[ns]'
        }
        
        if new_type in type_mapping:
            df_result[column] = df_result[column].astype(type_mapping[new_type])
        
        self._add_step(
            "Change Type", 
            df_result, 
            f"–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö",
            {'column': column, 'old_type': str(self.current_df[column].dtype), 'new_type': new_type}
        )
        return self
    
    def group_aggregate(self, group_by: list, aggregations: dict):
        """–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        df_result = self.current_df.groupby(group_by).agg(aggregations).reset_index()
        
        # –£–ø—Ä–æ—â–∞–µ–º –∏–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫ –ø–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        if isinstance(df_result.columns, pd.MultiIndex):
            df_result.columns = [f"{col[0]}_{col[1]}" if col[1] else col[0] for col in df_result.columns]
        
        self._add_step(
            "Group & Aggregate", 
            df_result, 
            f"–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è",
            {'group_by': group_by, 'aggregations': aggregations}
        )
        return self
    
    def sort_data(self, by: list, ascending: bool = True):
        """–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        df_result = self.current_df.sort_values(by=by, ascending=ascending)
        self._add_step(
            "Sort", 
            df_result, 
            f"–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö",
            {'sort_by': by, 'ascending': ascending}
        )
        return self
    
    def get_result(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
        return self.current_df
    
    def save_result(self, output_path: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ CSV"""
        self.current_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")


def excel_powerquery_etl():
    """
    ETL –ø—Ä–æ—Ü–µ—Å—Å —Å Excel –≤ —Å—Ç–∏–ª–µ Power Query
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    EXCEL_PATH = '/opt/airflow/excel_data/test.xlsx'
    OUTPUT_PATH = '/opt/airflow/data/powerquery_output.csv'
    
    print("üöÄ –ó–ê–ü–£–°–ö POWER QUERY ETL –î–õ–Ø EXCEL")
    print("=" * 80)
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞
        pq = ExcelPowerQuery(EXCEL_PATH)
        
        # –ü–ê–ô–ü–õ–ê–ô–ù –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ô
        result = (pq
            # –®–∞–≥ 1: –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞
            .remove_empty_rows()
            .remove_empty_columns()
            .clean_column_names()
            
            # –®–∞–≥ 2: –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –≤ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            .rename_columns({
                '‚Ññ': 'id',
                '—Å—Ç–∞—Ç—å—è': 'article', 
                '–ü–ª–∞–Ω': 'plan',
                '–§–∞–∫—Ç': 'fact',
                '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ': 'deviation',
                'column_5': 'deviation_percent'
            })
            
            # –®–∞–≥ 3: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è)
            .filter_rows('plan.notna() and fact.notna()')
            
            # –®–∞–≥ 4: –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤
            .change_data_type('id', 'int')
            .change_data_type('plan', 'float')
            .change_data_type('fact', 'float')
            .change_data_type('deviation', 'float')
            
            # –®–∞–≥ 5: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª—è–µ–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            .add_calculated_column('plan_fact_ratio', lambda x: (x['fact'] / x['plan'] * 100).round(2))
            .add_calculated_column('achievement_status', lambda x: np.where(
                x['fact'] >= x['plan'], 'achieved', 'not_achieved'
            ))
            .add_calculated_column('absolute_deviation', lambda x: abs(x['deviation']))
            
            # –®–∞–≥ 6: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –±–∏–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª–∞–º
            .filter_rows('plan > 0 and fact > 0')
            .filter_rows('absolute_deviation > 0')  # –¢–æ–ª—å–∫–æ —Å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è–º–∏
            
            # –®–∞–≥ 7: –ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            .group_aggregate(
                group_by=['achievement_status'],
                aggregations={
                    'plan': ['sum', 'mean'],
                    'fact': ['sum', 'mean'],
                    'absolute_deviation': ['mean', 'max'],
                    'id': 'count'
                }
            )
            
            # –®–∞–≥ 8: –§–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
            .rename_columns({
                'id_count': 'articles_count',
                'plan_sum': 'total_plan',
                'fact_sum': 'total_fact',
                'plan_mean': 'avg_plan',
                'fact_mean': 'avg_fact',
                'absolute_deviation_mean': 'avg_deviation',
                'absolute_deviation_max': 'max_deviation'
            })
            .sort_data(['articles_count'], ascending=False)
        )
        
        # –ü–û–ö–ê–ó–´–í–ê–ï–ú –í–ï–°–¨ –ü–ê–ô–ü–õ–ê–ô–ù
        pq.show_pipeline()
        
        # –°–û–•–†–ê–ù–Ø–ï–ú –†–ï–ó–£–õ–¨–¢–ê–¢
        pq.save_result(OUTPUT_PATH)
        
        # –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢
        final_df = pq.get_result()
        print("\n" + "=" * 80)
        print("‚úÖ ETL –ü–†–û–¶–ï–°–° –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù")
        print("=" * 80)
        print(f"üìÅ –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª: {EXCEL_PATH}")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç: {OUTPUT_PATH}")
        print(f"üìä –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {final_df.shape}")
        print(f"üî¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤: {len(pq.steps)}")
        print(f"üéØ –§–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
        print(final_df.to_string(index=False))
        
        return final_df
        
    except Exception as e:
        print(f"‚ùå –û–®–ò–ë–ö–ê –í ETL –ü–†–û–¶–ï–°–°–ï: {e}")
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —à–∞–≥–∏ –¥–æ –æ—à–∏–±–∫–∏
        if 'pq' in locals():
            pq.show_pipeline()
        raise


def debug_excel_transformation(step_number: int = None):
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
    """
    EXCEL_PATH = '/opt/airflow/excel_data/test.xlsx'
    
    pq = ExcelPowerQuery(EXCEL_PATH)
    
    if step_number:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —à–∞–≥
        if step_number <= len(pq.steps):
            step = pq.steps[step_number - 1]
            print(f"üîç –î–ï–ë–ê–ì –®–ê–ì–ê {step_number}: {step['description']}")
            print(f"–î–∞–Ω–Ω—ã–µ –Ω–∞ —ç—Ç–æ–º —à–∞–≥–µ:")
            print(step['preview_data'])
        else:
            print("‚ùå –®–∞–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    else:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ —à–∞–≥–∏
        pq.show_pipeline()


# Airflow DAG
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
    'excel_powerquery_etl',
    default_args=default_args,
    description='Power Query-style ETL –¥–ª—è Excel —Ñ–∞–π–ª–æ–≤ —Å –ø–æ—à–∞–≥–æ–≤–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π',
    schedule_interval=timedelta(days=1),
    catchup=False,
    tags=['excel', 'powerquery', 'etl', 'pandas'],
) as dag:

    etl_task = PythonOperator(
        task_id='excel_powerquery_processing',
        python_callable=excel_powerquery_etl,
    )

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    debug_task = PythonOperator(
        task_id='debug_transformations',
        python_callable=debug_excel_transformation,
        op_kwargs={'step_number': None},  # –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —à–∞–≥
    )

    etl_task >> debug_task